{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallelization Lab\n",
    "In this lab, you will be leveraging several concepts you have learned to obtain a list of links from a web page and crawl and index the pages referenced by those links - both sequentially and in parallel. Follow the steps below to complete the lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Use the requests library to retrieve the content from the URL below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = 'https://en.wikipedia.org/wiki/Data_science'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "response = requests.get(url)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Use BeautifulSoup to extract a list of all the unique links on the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html class=\"client-nojs\" dir=\"ltr\" lang=\"en\">\n",
      " <head>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "soup = BeautifulSoup(response.text, 'lxml')\n",
    "print(soup.prettify()[0:100])\n",
    "tags = soup.find_all(\"a\", {\"href\": True})\n",
    "l_unique_links = list(set([tag.get('href') for tag in tags]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Use list comprehensions with conditions to clean the link list.\n",
    "There are two types of links, absolute and relative. Absolute links have the full URL and begin with http while relative links begin with a forward slash (/) and point to an internal page within the wikipedia.org domain. Clean the respective types of URLs as follows.\n",
    "\n",
    "Absolute Links: Create a list of these and remove any that contain a percentage sign (%).\n",
    "\n",
    "Relative Links: Create a list of these, add the domain to the link so that you have the full URL, and remove any that contain a percentage sign (%).\n",
    "\n",
    "Combine the list of absolute and relative links and ensure there are no duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = 'http://wikipedia.org'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "l_absolute_links = [l for l in l_unique_links if (l.startswith(\"http\") and \"%\" not in l)]\n",
    "l_relative_links = [domain + l for l in l_unique_links if (l.startswith(\"/\") and \"%\" not in l and not l.startswith(\"//\"))]\n",
    "l_links = list(set(l_absolute_links + l_relative_links))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Use the os library to create a folder called wikipedia and make that the current working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "try: \n",
    "    os.mkdir('./wiki')\n",
    "except OSError as error: \n",
    "    print(error)\n",
    "    \n",
    "try: \n",
    "    os.chdir('./wiki')\n",
    "except OSError as error: \n",
    "    print(error)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Write a function called index_page that accepts a link and does the following.\n",
    "Tries to request the content of the page referenced by that link.\n",
    "\n",
    "Slugifies the filename using the slugify function from the python-slugify library and adds a .html file extension.\n",
    "\n",
    "      If you don't already have the python-slugify library installed, you can pip install it as follows:\n",
    "      $ pip3 install python-slugify.\n",
    "\n",
    "      To import the slugify function, you would do the following: from slugify import slugify.\n",
    "\n",
    "      You can then slugify a link as follows slugify(link).\n",
    "\n",
    "Creates a file in the wikipedia folder using the slugified filename and writes the contents of the page to the file.\n",
    "\n",
    "If an exception occurs during the process above, just pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from slugify import slugify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "def index_page(link):\n",
    "    try:\n",
    "        page = requests.get(link, 'lxml')\n",
    "        filename = slugify(link) + '.html'\n",
    "        file = open(filename, \"w\")\n",
    "        file.write(page.text)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Sequentially loop through the list of links, running the index_page function each time.\n",
    "Remember to include %%time at the beginning of the cell so that it measures the time it takes for the cell to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "%%time\n",
    "\n",
    "for link in l_links:\n",
    "    index_page(link)\n",
    "    \n",
    "# CPU time: user 44 s, sys: 4.24 s, total: 48.2 s\n",
    "# Wall time: 7min 1s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Perform the page indexing in parallel and note the difference in performance.\n",
    "Remember to include %%time at the beginning of the cell so that it measures the time it takes for the cell to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    os.mkdir('./wikipedia_parallelization')\n",
    "except OSError as error: \n",
    "    print(error)\n",
    "    \n",
    "try: \n",
    "    os.chdir('./wikipedia_parallelization')\n",
    "except OSError as error: \n",
    "    print(error)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1 s\n",
      "Wall time: 10.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "process_list = []\n",
    "for link in l_links:\n",
    "  p = multiprocessing.Process(target = index_page, args = (link,))\n",
    "  p.start()\n",
    "  process_list.append(p)\n",
    "\n",
    "for process in process_list:\n",
    "  process.join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "3f9e526264d578bc1229c9acd1c854751b6b292fe01e951c245e924c89a05e3f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
